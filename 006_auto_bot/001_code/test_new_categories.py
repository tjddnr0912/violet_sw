#!/usr/bin/env python3
"""
Test new stock and crypto categories
"""

import os
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'

from v3.config import config
from v3.news_aggregator import NewsAggregator
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

print("=" * 60)
print("Testing New Stock & Crypto Categories")
print("=" * 60)

# Test stock category feeds
print("\nğŸ“ˆ ì£¼ì‹ ì¹´í…Œê³ ë¦¬ RSS í”¼ë“œ:")
for url in config.NEWS_SOURCES_BY_CATEGORY['ì£¼ì‹']:
    print(f"  - {url}")

print("\nğŸ’° ì•”í˜¸í™”í ì¹´í…Œê³ ë¦¬ RSS í”¼ë“œ:")
for url in config.NEWS_SOURCES_BY_CATEGORY['ì•”í˜¸í™”í']:
    print(f"  - {url}")

# Test fetching news
print("\n" + "=" * 60)
print("Fetching sample news from new categories...")
print("=" * 60)

# Create aggregator with only stock and crypto feeds
test_feeds = (
    config.NEWS_SOURCES_BY_CATEGORY['ì£¼ì‹'][:2] +  # First 2 stock feeds
    config.NEWS_SOURCES_BY_CATEGORY['ì•”í˜¸í™”í'][:2]  # First 2 crypto feeds
)

aggregator = NewsAggregator(test_feeds, category_map=config.CATEGORY_MAP)

# Fetch news (last 7 days to ensure we get some results)
news_items = aggregator.fetch_news(hours_limit=168)

print(f"\nâœ… Fetched {len(news_items)} news items")

# Group by category
from collections import defaultdict
by_category = defaultdict(list)

for item in news_items:
    by_category[item['category']].append(item)

# Display results
for category, items in by_category.items():
    print(f"\n{'='*60}")
    print(f"{category} ì¹´í…Œê³ ë¦¬: {len(items)}ê°œ ë‰´ìŠ¤")
    print(f"{'='*60}")

    for i, item in enumerate(items[:3], 1):  # Show first 3
        print(f"{i}. [{item['source']}] {item['title'][:60]}...")
        print(f"   Published: {item['published_date']}")
        print(f"   Link: {item['link'][:80]}...")
        print()

print("=" * 60)
print("âœ… Test completed successfully!")
print("=" * 60)
